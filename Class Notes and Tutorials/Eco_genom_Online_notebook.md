  

### Ecological Genomics Notebook   
### Author: R Kirsten Tyler: A PhD student at UVM studying invasive plants


## Overall Description of notebook      

Class notes on learning the programs and methods involved in analyzing genomic data to answer our big questions!


## Date started: (January 2017)   
## Date end:   (year-month-day)    

## Philosophy   
Science should be reproducible and one of the best ways to achieve this is by logging research activities in a notebook. Because science/biology has increasingly become computational, it is easier to document computational projects in an electronic form, which can be shared online through Github.    

### Helpful features of the notebook     

**It is absolutely critical for your future self and others to follow your work.**     

* The notebook is set up with a series of internal links from the table of contents.    
* All notebooks should have a table of contents which has the "Page", date, and title (information that allows the reader to understand your work).     
* Also, one of the perks of keeping all activities in a single document is that you can **search and find elements quickly**.     
* You can document anything you'd like, aside from logging your research activities. For example:
	* feel free to log all/any ideas for your research project([example](https://github.com/adnguyen/Notebooks_and_Protocols/blob/master/2016_notebook.md#page-39-2016-06-13-post-doc-project-idea-assessing-current-impacts-of-climate-change-in-natural-populations)) as an entry,     
	* or write down notes for a paper([example](https://github.com/adnguyen/Notebooks_and_Protocols/blob/master/2016_notebook.md#id-section36).      

* Lastly, you can share specific entries because of the three "#" automatically creates a link when the notebook renders on github.      


<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.  


### Table of contents for 60 entries (Format is *Page: Date(with year-month-day). Title*)        
* [Page 1: 2017-01-18](#id-section1). First class; intros (from Andrew)
* [Page 2: 2016-6-16](#id-section2). Eco Geno in class notes 2/6/17
* [Page 3:](#id-section3).
* [Page 4:](#id-section4).
* [Page 5:](#id-section5).
* [Page 6:](#id-section6).
* [Page 7:](#id-section7).
* [Page 8:](#id-section8).
* [Page 9:](#id-section9).
* [Page 10:](#id-section10).
* [Page 11:](#id-section11).
* [Page 12:](#id-section12).
* [Page 13:](#id-section13).
* [Page 14:](#id-section14).
* [Page 15:](#id-section15).
* [Page 16:](#id-section16).
* [Page 17:](#id-section17).
* [Page 18:](#id-section18).
* [Page 19:](#id-section19).
* [Page 20:](#id-section20).
* [Page 21:](#id-section21).
* [Page 22:](#id-section22).
* [Page 23:](#id-section23).
* [Page 24:](#id-section24).
* [Page 25:](#id-section25).
* [Page 26:](#id-section26).
* [Page 27:](#id-section27).
* [Page 28:](#id-section28).
* [Page 29:](#id-section29).
* [Page 30:](#id-section30).
* [Page 31:](#id-section31).
* [Page 32:](#id-section32).
* [Page 33:](#id-section33).
* [Page 34:](#id-section34).
* [Page 35:](#id-section35).
* [Page 36:](#id-section36).
* [Page 37:](#id-section37).
* [Page 38:](#id-section38).
* [Page 39:](#id-section39).
* [Page 40:](#id-section40).
* [Page 41:](#id-section41).
* [Page 42:](#id-section42).
* [Page 43:](#id-section43).
* [Page 44:](#id-section44).
* [Page 45:](#id-section45).
* [Page 46:](#id-section46).
* [Page 47:](#id-section47).
* [Page 48:](#id-section48).
* [Page 49:](#id-section49).
* [Page 50:](#id-section50).
* [Page 51:](#id-section51).
* [Page 52:](#id-section52).
* [Page 53:](#id-section53).
* [Page 54:](#id-section54).
* [Page 55:](#id-section55).
* [Page 56:](#id-section56).
* [Page 57:](#id-section57).
* [Page 58:](#id-section58).
* [Page 59:](#id-section59).
* [Page 60:](#id-section60).

------
<div id='id-section1'/>
### Page 1: 2016-07-18. Ecological genomics, first class

### **Steve and Melissa's intro**    
* Steve: It is a young field, trying to establish it's own identity    
	* Ecological genomics institute, KSU: emphasis on adaptation to environment   
	* Gordon Research Conference: Integrating different levels of biological organization on **ANY SYSTEM**; approach and tool focused! Field going towards new data and new analytic techniques  
	* Intro to eco genomics, oxford press; Using technology to address ecological issues such as nutrient cycling, population structure, life history vairation , trophic interaction, stress responess, and adpatation to environmental change   

* DATA driven: next gen sequencing revolutionizes biology
	* creats a new problem--large datasets!!! how to make sense? 
	* not data limited and potentially computationally limited   

* Where is the field headed    
	* Molecular Ecology Journal(flagship journal representative o the field)  
		* ALL systems:  corals, protists, daphnia, coral, lemurs, dandelions, steve studies trees 
		* model organism constraint disappearing!   
	* What types of questions are asked?  
		* How do genes correspond with circadian rythm?  
		* How does the microbiome influence the organism? 
		* How does epigenetic variation influence evolutionary responses? or contribute to phenotypic variation?  
		* What are the patterns of genetic diversity that can give us insights on population dynamics?  
		* What are constraints and tradeoffs and genetic mechanisms of traits? 

* Methods?   
	* De novo genome assembly; sequencing a DNA book from scratch!!    
		* RNA-seq; transcriptomic profiling     
	* 16 s metagenomic sequencing      
	* Rad-seq/GBS for estiamting population structure and genetic diversity     

* Proccesses studied?    
	* All evo and eco stuff; speciation, hybridization, local adaptation, genetic basis of local adaptation, genetic architecture of complex phenotypes, genes controlling host-pathogen evolutionary dynamics, pop structure, gene flow, epigenetics     
	
* Goals of the course!    
	1. Learn how ecology and genomes shape each other   
	2. Think creatively about major questions, and pose testable hypotheses to those questions using appropriate genomic data    
	3. Think about careful experimental design and statistical analysis---shown by reading papers   
	4. Achive working knowledge and level of comfort for bioinformatics routines for ecological genomics studies   
	
### Melissa background	  

**Background, what drove Melissa and Steve to ecological genomics?**       

Melissa read a cool paper that scales from analyzing a few loci to the whole genome.   

One figure popped out at her, FST (developed by Sewell Wright) histogram.   FST of 1= complete differentiation, FST of 0 = no diff. FST described as **Alleles in space**. From this histogram, Melissa was struck by how you can separate out neutral from selective ones.  

Melissa has a data set with 96 sea stars and then the 16s microbiome. Would be cool to see if there is heritability in some bactera

### Steve background   

* Inspired by Yanis Antonivics (an **OG**)   
* At the time, just so stories: **Adaptatationist programme**    
	* Just go out and go by feeling in a natural history way and prescribe an adaptation story   
	* Janis wrote a creed to quantify the operational relationship between traits, environment, and genetics     
* Yanis was on Steve's committee and Steve was interested in adaptation with respect to invasion biology because organisms need to respond to novel environments     
	* Phenotypes can relate to the environment, but what is the genetic basis of local adaptation (in situ)? There are other confounding issues: demographic effects, plasticity     
* Steve thinks about environment-phenotype-genetics triangle. Basically a path diagram that feeds back on each other.    
	* Relationship between genes and phenotype ---GWAS (Genome wide association study)    
	* Relationship between genetics and environment --- Fst, clines between allele frequencies and environment    
* Invasion history is tough because of demographic history    
* He decided to focus on trees; large population size, straddle huge environmental gradients so the opportunity for selection is high   
	* positive relationship between Growing season length and traits    
	* Did a  reciprocal transplant of different populations to identify the extent of local adaptation in large established common gardens    
	* SK does GBS (genotype by sequencing)      
	* Problem with field: validating key gene candidates            
  

------
<div id='id-section2'/>
### Page 2: 2/6/17 Eco Geno in class notes 

---
**starting a de novo assembly using Trinity**  

*logging in the to the server* 
```
kirstensmac$ ssh rtyler1@pbio381.uvm.edu
rtyler1@pbio381.uvm.edu's password: xxxxx 
```

*finding the fastq files*
```
[rtyler1@pbio381 ~]$ cd /data/project_data/fastq
[rtyler1@pbio381 fastq]$ ll  
```

*examples of files*
```
-rw-r--r--. 1 mlloyd   users 1947250259 Feb  5 15:21 07_5-08_S_1_R1.fq.gz
-rw-r--r--. 1 mlloyd   users 2161217591 Feb  5 15:22 07_5-08_S_1_R2.fq.gz
-rw-r--r--. 1 mlloyd   users  234706841 Feb  2 12:18 07_5-11_S_4_R1.fq.gz
-rw-r--r--. 1 mlloyd   users  247650662 Feb  2 12:18 07_5-11_S_4_R2.fq.gz  
```
  
-R1 and R2 = paired reads for each sample  
-S scale 1-4 = 1 lesion, multiple lesions, missing arm, falling apart 

*my sample for evaluating cleaning and evaluating again*  
```
-rw-r--r--. 1 mlloyd   users 1022067764 Feb  5 15:22 19_5-11_H_0_R1.fq.gz
-rw-r--r--. 1 mlloyd   users 1093493001 Feb  5 15:23 19_5-11_H_0_R2.fq.gz
```

*let's take a look at the files*  

The fast file format has 4 lines for each read: the read identifier, the read sequence, “+”, and a sequence of quality scores for each base.

[A useful table of (Quality) Phred scores](http://www.drive5.com/usearch/manual/quality_score.html)

```
[rtyler1@pbio381 fastq]$ zcat 19_5-11_H_0_R1.fq.gz | head  

@J00160:63:HHHT2BBXX:1:1101:25591:1244 1:N:0:ATTACTCG+CTTCGCCT
GNCAGTTCCATTCCACACTTTCAAGATACCNTANATGCNAGTNCCNTTCCACACNTTCNANGCACTCCTCTATGCCCACCTGTNTTNATTTCANTCCTAAT
+
<#AFFJFFJFJJJJJJJJJJJJJJJJJJJJ#JJ#JJJJ#JJJ#JJ#JJJJJJJJ#JJJ#J#AJJJFJJ7JJJJJJJAJJFJJJ#JF#JJJFAJ#JFFAJF-
@J00160:63:HHHT2BBXX:1:1101:27519:1244 1:N:0:ATTACTCG+CTTCGCCT
CNGATCATTAAAATATCCACGAAACAATATNAAATCACACGATATTTTTGTTTAAATANCTTACATAATTAGTATATCAATATTGCCGTGACANCCAATGT
+
A#AFFJJJJJJJJJJJJJJJJJJJJJJJJJ#JJJJJJJJJJJJJJJJJJJJJJJJJJJ#JJJJJJJJJJJJJJJJJJJJJJJJJJJAJJJFJ7#FFFJJFJ
@J00160:63:HHHT2BBXX:1:1101:28270:1244 1:N:0:ATTACTCG+CTTCGCCT
CNTTTATTAACAACACGTTTCCTGACTGACNGTTGCATGCATCTGTCTGAGATTTTCTTATTTGTTCCCCTCCCCATGGTGGATCTATTCCCGACCCATCA  
```

*using vim in terminal, we will change the file name to our own file name*
```
[rtyler1@pbio381 scripts]$ vim trim_example.sh  
```
 - press i to insert (editing the file name)  
 - press esc then  
 - w to save  
 - q to quit  
 
*running trimmomatic to clean the file*  
 ```
[rtyler1@pbio381 scripts]$ bash trim_example.sh
```
*running fastq to look at the quality of the data*
```
fastqc FILENAME.fq.gz
```
*after that's done, move the .html file to your computer using the scpcommand from your machine (open another terminal)*

```
scp mpespeni@pbio381.uvm.edu:/data/project_data/fastq/38_6-24_S_5_R2_fastqc.html
```

------
<div id='id-section3'/>
### Page 3: 2/8/17 Eco Geno in class notes

---
**Continuing with RNAseq analysis**

- finish cleaning (trimomatic)
- fastqc (visual)
- make table of # reads
- design assembly tests
- start assemblies
- evaluate assemblies

*In terminal, some useful commands*  

The "move" command can change the name of your file OR move it to a new directory (or both at the same time)   

```{}
mv FILENAME NEWFILENAME
```
*running fastq to look at the quality of the data*   

```{}
fastqc FILENAME.fq.gz   
```

*after that's done, move the .html file to your computer using the scp command from your machine (hint: open another terminal but DON'T sign in to the server)*   

```{}
[rtyler1@pbio381 ~]$ scp rtyler1@pbio381.uvm.edu:/data/project_data/fastq/cleanreads/19_5-11_H_0_R2_clean_paired_fastqc.html .
```

We will only use the paired reads to assemble

What would change the assembly? 
- varied parameters

------
<div id='id-section4'/>
### Page 4: 2/13/17 Eco Geno in class notes

---
**Making a reference transcriptome and Mapping reads to the reference transcriptome**

*Using TransDecoder to predict longest Open Reading Frames (ORF's)*

```{}
wget https://github.com/TransDecoder/TransDecoder/archive/v3.0.1.zip
```

*Choose an individual in your sample to create a reference genome and compare others to it*   

-----Melissa chose one sample from our starfish data-----   
-it had many samples (all 5 time points)
-it had enough reads (50 million) which is optimal for a transcriptome assembly

*Evaluate the "longest_orfs.cds" assembly after running Transdecoder*

```{}
$ /data/popgen/trinityrnaseq-Trinity-v2.3.2/util/TrinityStats.pl longest_orfs.cds
```

*Also evaluate the assembly using blastp to compare to uniprot_swissprot database*

```{}wget https://github.com/Trinotate/Trinotate/releases

# Run the script to download the relevant databases.
/data/popgen/Trinotate-3.0.1/admin/Build_Trinotate_Boilerplate_SQLite_db.pl  Trinotate

*To improve assembly*   
(1) using more reads from other individuals or trying a different individual   
(2) changing the cleaning and assembly parameters. We can evaluate based on the percentage of genes that have good blastp hits and the percentage of single copy orthologs included in the reference (for example using the new program (BUSCO)[http://busco.ezlab.org/]   

**Map reads from individual samples to reference transcriptome using program BWA**   

Right now, we are mapping the reads of our file to the reference transcriptome that Melissa made already. First, rename the file. Then run the program BWA and generate a text file.

*rename file*   
```{}
[rtyler1@pbio381 ~]$ cd /data/scripts/
[rtyler1@pbio381 scripts]$ cp bwaaln.sh ~/scripts/bwaaln_tyler.sh
```
*Also, THERE IS AN ENORMOUS SNOWSTORM HAPPENING OUTSIDE RIGHT NOW*   

*run file and generate a text file*   
```{}
[rtyler1@pbio381 scripts]$ bash bwaaln_tyler.sh >> bwaoutput_tyler.txt
```

This will generate a SAM file. 
*To check out our .sam file*
```{}
head *.sam
```

-Each read gets a flag that describes how well it mapped [What the numbers mean](http://seqanswers.com/forums/showthread.php?t=17314)   

-Map quality is the 5th column in the .sam file

------
<div id='id-section5'/>
### Page 5: 2/15/17 Eco Geno in class notes

---
**We have a SAM file....now what?**    

A tab delimited file that tells us everything we want to know about how well (or whether or not) our fastq file mapped to our reference

*Get to your SAM file in scripts*   

```{}
[rtyler1@pbio381 ~]$ cd scripts
[rtyler1@pbio381 scripts]$ ll
total 8521880
-rw-r--r--. 1 rtyler1 users 8491636603 Feb 13 11:31 19_5-11_H_0_bwaaln.sam
-rw-r--r--. 1 rtyler1 users  114638736 Feb 13 11:20 19_5-11_H_0_R1.fq.gz_left_clean_paired.fq.sai
-rw-r--r--. 1 rtyler1 users  120112320 Feb 13 11:28 19_5-11_H_0_R2.fq.gz_right_clean_paired.fq.sai
-rwxr-xr-x. 1 rtyler1 users        914 Feb 13 11:08 bwaaln_tyler.sh
-rw-r--r--. 1 rtyler1 users         97 Feb 13 11:12 bwaoutput_tyler.txt
-rwxr--r--. 1 rtyler1 users        811 Feb  6 11:39 trim_example.sh
[rtyler1@pbio381 scripts]$ 
```

The SAM file includes: 

 - the read, aka. query, name,
 - a FLAG (number with information about mapping success and orientation and whether the read is the left or right read),
 - the reference sequence name to which the read mapped
 - the leftmost position in the reference where the read mapped
 - the mapping quality (Phred-scaled)
 - a CIGAR string that gives alignment information (how many bases Match (M), where there’s an Insertion (I) or Deletion (D))
 - an ‘=’, mate position, inferred insert size (columns 7,8,9),
 - the query sequence and Phred-scaled quality from the FASTQ file (columns 10 and 11),
 - then Lots of good information in TAGS at the end, if the read mapped,  - including whether it is a unique read (XT:A:U), the number of best hits (X0:i:1), the number of suboptimal hits (X1:i:0).

*Here's a view of my SAM file*   

```{}
J00160:63:HHHT2BBXX:4:2228:14438:49019  81      TRINITY_DN30214_c0_g1::TRINITY_DN3
J00160:63:HHHT2BBXX:4:2228:14438:49019  161     TRINITY_DN30214_c0_g1::TRINITY_DN3
J00160:63:HHHT2BBXX:4:2228:14823:49019  77      *       0       0       *       *
J00160:63:HHHT2BBXX:4:2228:14823:49019  141     *       0       0       *       *
J00160:63:HHHT2BBXX:4:2228:17036:49019  77      *       0       0       *       *
J00160:63:HHHT2BBXX:4:2228:17036:49019  141     *       0       0       *       *
J00160:63:HHHT2BBXX:4:2228:26332:49019  77      *       0       0       *       *
J00160:63:HHHT2BBXX:4:2228:26332:49019  141     *       0       0       *       *
J00160:63:HHHT2BBXX:4:2228:29173:49019  77      *       0       0       *       *
```

The second column is the flag number

*To look at SAM files and decode their flags*   

```{}
tail -n 100 YOURFILENAME.sam > tail.sam
vim tail.sam

:set nowrap
```

Go to [this website](https://broadinstitute.github.io/picard/explain-flags.html) to explain the SAM flags.

Type in your SAM flag number and this cool website will list the properties of your read based on the flag number. Cool.

BWA website will explain the codes associated with reads
[BWA Website](http://bio-bwa.sourceforge.net/bwa.shtml)   

*BWA generates the following optional fields*

Tags starting with ‘X’ are specific to BWA.

Tag	Meaning
NM	Edit distance
MD	Mismatching positions/bases
AS	Alignment score
BC	Barcode sequence
X0	Number of best hits
X1	Number of suboptimal hits found by BWA
XN	Number of ambiguous bases in the referenece
XM	Number of mismatches in the alignment
XO	Number of gap opens
XG	Number of gap extentions
XT	Type: Unique/Repeat/N/Mate-sw
XA	Alternative hits; format: (chr,pos,CIGAR,NM;)*
XS	Suboptimal alignment score
XF	Support from forward/reverse alignment
XE	Number of supporting seeds

*Now let’s see how many of our reads map uniquely*   

The code:
```{}
The code XT
$ grep -c XT:A:U YOURFILENAME.sam 
1177827

$ grep -c X0:i:1 YOURFILENAME.sam
1182952
```

For my SAM file: 

```{}
[rtyler1@pbio381 scripts]$ grep -c XT:A:U 19_5-11_H_0_bwaaln.sam
2578534
```
So we see here that I have 2.5 million uniquely mapped reads.   

```{}
[rtyler1@pbio381 scripts]$ grep -c X0:i:1 19_5-11_H_0_bwaaln.sam
2597995
```
So we see here that I have about 2.6 million "best hits"

*Now we will look at the number of reads that map to each gene*

From Melissa: 

We will use a custom python script (by my friend Dan Barshis and published with the Simple Fool’s Guide to Population Genomics) called countxpression.py. This script will take any number of input *.sam files and, for each .sam file, extract the number of reads that map to each gene (i.e. the “counts”). It will also generate a summary output of useful information including proportion of quality read alignments. The script requires 4 input variables: mapqualitythreshold, lengththreshold, outputstatsfilename, anynumberofinputfiles.

Let's do it. 

```{}
cd /data/scripts
cp countxpression_PE.py ~/scripts      #or copy to your directory with the .sam file

python countxpression_PE.py 20 35 countstatssummary.txt 19_5-11_H_0_bwaaln.sam
```








------
<div id='id-section6'/>
### Page 6:
------
<div id='id-section7'/>
### Page 7:
------
<div id='id-section8'/>
### Page 8:
------
<div id='id-section9'/>
### Page 9:
------
<div id='id-section10'/>
### Page 10:
------
<div id='id-section11'/>
### Page 11:
------
<div id='id-section12'/>
### Page 12:
------
<div id='id-section13'/>
### Page 13:
------
<div id='id-section14'/>
### Page 14:
------
<div id='id-section15'/>
### Page 15:
------
<div id='id-section16'/>
### Page 16:
------
<div id='id-section17'/>
### Page 17:
------
<div id='id-section18'/>
### Page 18:
------
<div id='id-section19'/>
### Page 19:
------
<div id='id-section20'/>
### Page 20:
------
<div id='id-section21'/>
### Page 21:
------
<div id='id-section22'/>
### Page 22:
------
<div id='id-section23'/>
### Page 23:
------
<div id='id-section24'/>
### Page 24:
------
<div id='id-section25'/>
### Page 25:
------
<div id='id-section26'/>
### Page 26:
------
<div id='id-section27'/>
### Page 27:
------
<div id='id-section28'/>
### Page 28:
------
<div id='id-section29'/>
### Page 29:
------
<div id='id-section30'/>
### Page 30:
------
<div id='id-section31'/>
### Page 31:
------
<div id='id-section32'/>
### Page 32:
------
<div id='id-section33'/>
### Page 33:
------
<div id='id-section34'/>
### Page 34:
------
<div id='id-section35'/>
### Page 35:
------
<div id='id-section36'/>
### Page 36:
------
<div id='id-section37'/>
### Page 37:
------
<div id='id-section38'/>
### Page 38:
------
<div id='id-section39'/>
### Page 39:
------
<div id='id-section40'/>
### Page 40:
------
<div id='id-section41'/>
### Page 41:
------
<div id='id-section42'/>
### Page 42:
------
<div id='id-section43'/>
### Page 43:
------
<div id='id-section44'/>
### Page 44:
------
<div id='id-section45'/>
### Page 45:
------
<div id='id-section46'/>
### Page 46:
------
<div id='id-section47'/>
### Page 47:
------
<div id='id-section48'/>
### Page 48:
------
<div id='id-section49'/>
### Page 49:
------
<div id='id-section50'/>
### Page 50:
------
<div id='id-section51'/>
### Page 51:
------
<div id='id-section52'/>
### Page 52:
------
<div id='id-section53'/>
### Page 53:
------
<div id='id-section54'/>
### Page 54:
------
<div id='id-section55'/>
### Page 55:
------
<div id='id-section56'/>
### Page 56:
------
<div id='id-section57'/>
### Page 57:
------
<div id='id-section58'/>
### Page 58:
------
<div id='id-section59'/>
### Page 59:
------
<div id='id-section60'/>
### Page 60:

------
